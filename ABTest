

#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

# chapter 3 The design and application of A/B testing

# chapter 3.1  Introduction to A/B testing

# A/B test is an experiment in which you test two different values of the same variable against one another
# randomly assign users to control and test group
# good problems for A/B testing are those where users are being impacted in an individual way
# bad problems for A/B testing are those in which there are network effects of users, dating app

demographics_data = pd.read_csv('user_demographics.csv')
demographics_data.head(4)
paywall_views = pd.read.csv('paywall_views.csv')
paywall_views.head(4)

# response variable: KPI or somthing directly related to KPI, simple to measure
# factors that impact our response, color of paywall
# experiment units: the unit over which metrics are measured before aggregating over the control or treatment group overall, users

purchase_data = demogrphics_data.merge(paywall_views, how = 'left', on = ['uid'])
purchase_data_agg = purchase_data.groupby(by = ['uid'], as_index=False)
total_purchases = purchase_data_agg.purchase.sum()   #purchase field 0/1 value
total_purchases.purchase = np.where(np.isnan(total_purchase.purchase), 0, total_purchase.purchase)
total_purchase.purchase.mean()
min(total_purchase.purchase) #0
max(total_purchase.purchase) #17 varies a lot
# since the amount of time on our platform varies widely between users, so it's not meaningful to compare

# user-days as experiment unit: treat each user's action on a given day as a unique unit

purchase_data = demogrphics_data.merge(paywall_views, how = 'left', on = ['uid'])
purchase_data.date = purchase_data.date.dt.floor('d')
purchase_data_agg = purchase_data.groupby(by = ['uid', 'date'], as_index=False)
total_purchases = purchase_data_agg.purchase.sum()   #purchase field 0/1 value
total_purchases.purchase = np.where(np.isnan(total_purchase.purchase), 0, total_purchase.purchase)
total_purchase.purchase.mean()
min(total_purchase.purchase) #0
max(total_purchase.purchase) #3

## Experimental units: Revenue per user day
# Extract the 'day'; value from the timestamp
purchase_data.date = purchase_data.date.dt.floor('d')

# Replace the NaN price values with 0 
purchase_data.price = np.where(np.isnan(purchase_data.price), 0, purchase_data.price)

# Aggregate the data by 'uid' & 'date'
purchase_data_agg = purchase_data.groupby(by=['uid', 'date'], as_index=False)
revenue_user_day = purchase_data_agg.sum()

# Calculate the final average
revenue_user_day = revenue_user_day.price.mean()
print(revenue_user_day)

#########################################################################################
## chapter 3.2 preparing to run an A/B test
# there are 3 different consumable price points (price changed 3 times) which may factor into our test
# main concerns in designing a test
# 1. ensure test can be practically run 2. can derive meaningful results from it

# test sensitivity: what percentage of change would be meaningful to detect in response variable
# exercise: look at what different sensitivity look like for your experiment unit

# 1% , 10%, 20% change in revenue per user-day
revenue_user_day * 1.01 (1.1/1.2)

# it's important to understand the latent variability in the data
# standard deviation
purchase_variation = total_purchase.purchase.std()
# typically we will rely on the standard deviation of the test result in evaluating the test, use the value of the original data for planning
total_purchases = purchase_data_agg.purchase.sum()   #purchase field 0/1 value
total_purchases.purchase = np.where(np.isnan(total_purchase.purchase), 0, total_purchase.purchase)
avg_purchases = total_purchase.purchase.mean()

purchase_variation / avg_purchases # small is better

#### choosing experimental unit & response variable
purchase_data = demogrphics_data.merge(paywall_views, how = 'left', on = ['uid'])
purchase_data_agg = purchase_data.groupby(by = ['uid'], as_index=False)
conversion_rate = (sum(purchase_data.purchase)/purchase_data.purchase.count())
conversion_rate ## this is the baseline

#### Conversion rate sensitivities: to examine what that value becomes under different percentage lifts and look at how many more 
# conversions per day this change would result in.

# Merge and group the datasets
purchase_data = demographics_data.merge(paywall_views,  how='inner', on=['uid'])
purchase_data.date = purchase_data.date.dt.floor('d')

# Group and aggregate our combined dataset 
daily_purchase_data = purchase_data.groupby(by=['date'], as_index=False)
daily_purchase_data = daily_purchase_data.agg({'purchase': ['sum', 'count']})

# Find the mean of each field and then multiply by 1000 to scale the result ( a sample of 0.1% of our overall population )
daily_purchases = daily_purchase_data.purchase['sum'].mean()
daily_paywall_views = daily_purchase_data.purchase['count'].mean()
daily_purchases = daily_purchases * 1000
daily_paywall_views = daily_paywall_views * 1000

print(daily_purchases)
print(daily_paywall_views)

small_sensitivity = 0.1 (0.2/0.5)

# Find the conversion rate when increased by the percentage of the sensitivity above
small_conversion_rate = conversion_rate * (1 + small_sensitivity) 

# Apply the new conversion rate to find how many more users per day that translates to
small_purchasers = daily_paywall_views * small_conversion_rate

# Subtract the initial daily_purcahsers number from this new value to see the lift
purchaser_lift = small_purchasers - daily_purchases

print(small_conversion_rate)
print(small_purchasers)
print(purchaser_lift)

############ Standard error for a conversion rate
## conversion rate p is normally distributed, SEM is std/sqrt(n) = sqrt( p*(1-p)/ n)
# Find the number of paywall views 
n = purchase_data.purchase.count()

# Calculate the quantitiy "v"
v = conversion_rate * (1 - conversion_rate) 

# Calculate the variance and standard error of the estimate
var = v / n 
se = var**0.5

print(var)
print(se)

#########################################################################################
## chapter 3.3 calculating sample sizes
# type I error: rejecting the null hypothesis when the null hypothesis is true
# type II error: retaining the false null hypothesis
# confidence level : the probability of not making a type I error (the hight cl the larger sample size needed , common 0.95)
# statistical power: the probability of finding statistically significant results when the null hypothesis is false

# power, confidence level, standard error, sensitivity and sample size
# as sample size goes up, so does power
# as confidence level goes up, power goes down

## sample size function 
def get_power(n, p1, p2, cl):
    alpha = 1-cl
    qu = stats.norm.ppf(1 - alpha/2) # scipy.stats.norm.ppf compute the inverse of the CDF of the standard normal distribution 
                                     # "percent point function" (ppf) is a terrible name. Most people in statistics just use "quantile function".
    diff = abs(p2-p1)
    
# ppf(q, loc=0, scale=1)  # Percent point function (inverse of cdf — percentiles)  it's Z score for standard normal  
# from scipy.stats import norm
# norm.ppf(.5)  # half of the mass is before zero
# 0.0

#The equivalent of the R pnorm() function is: scipy.stats.norm.cdf() with python 
#The equivalent of the R qnorm() function is: scipy.stats.norm.ppf() with python

pnorm
The function pnorm returns the integral from −∞ to q of the pdf of the normal distribution where q is a Z-score. Try to guess the value of pnorm(0). (pnorm has the same default mean and sd arguments as dnorm).
pnorm(0) # 0.5






